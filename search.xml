<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[博弈论的三个小游戏':' Bash游戏 威佐夫游戏 Nim游戏]]></title>
    <url>%2F2018%2F06%2F06%2F%E5%8D%9A%E5%BC%88%E8%AE%BA%E7%9A%84%E4%B8%89%E4%B8%AA%E5%B0%8F%E6%B8%B8%E6%88%8F%2F</url>
    <content type="text"><![CDATA[Bash游戏题目链接https://www.51nod.com/onlineJudge/questionCode.html#!problemId=1066 游戏规则有一堆石子一共N个，两人轮流拿，最少拿1个，最多拿K个，最后拿完石子的获胜。 证明如果N % (k+1) == 0，B必胜，否则A必胜 代码12345678910111213141516171819202122232425#include &lt;iostream&gt;#include &lt;algorithm&gt;#include &lt;cstring&gt;#include &lt;stdio.h&gt;#include &lt;string&gt;#include &lt;cmath&gt;#define ll long long#define mem(name,value) memset(name,value,sizeof(name))using namespace std;const int maxn = 105;int dp[maxn][maxn];int main()&#123; int t; cin &gt;&gt; t; while(t--)&#123; int n,k; cin &gt;&gt; n &gt;&gt; k; if(n % (k+1) == 0) cout &lt;&lt; "B" &lt;&lt;endl; else cout &lt;&lt; "A" &lt;&lt;endl; &#125; return 0;&#125; 威佐夫游戏题目链接https://www.51nod.com/onlineJudge/questionCode.html#!problemId=1072 游戏规则有两堆石子，两个人轮流从中取石子，可以从其中一堆中取不少于一个的石子或者从两堆石子中取相同的石子，最后把石子取完的人获胜。 证明后手胜利的情况为：(1, 2)(3, 5)(4, 7)(6, 10)(8, 13)(9, 15)(11, 18)(12, 20)。。。。。。令 m = (1 + sqrt(5))/2 (黄金分割数+1 = 1.618)观察发现每队整数之差为k，ak = [km] , bk = ak+k。因此只要判断 [(bk-ak)m] 是否== ak就可以了 代码12345678910111213141516171819202122232425262728#include &lt;iostream&gt;#include &lt;algorithm&gt;#include &lt;cstring&gt;#include &lt;stdio.h&gt;#include &lt;string&gt;#include &lt;cmath&gt;#define ll long long#define mem(name,value) memset(name,value,sizeof(name))using namespace std;const int maxn = 105;int dp[maxn][maxn];int ak, bk;double x;int main() &#123; int n; cin &gt;&gt; n; x = (1 + sqrt(5.0)) / 2; for(int i=0;i&lt;n;i++)&#123; scanf("%d %d", &amp;ak, &amp;bk); if(ak &gt; bk) swap(ak,bk); int k = bk - ak; if(ak == (int)(k * x)) printf("B\n"); else printf("A\n"); &#125;&#125; Nim游戏###题目链接https://www.51nod.com/onlineJudge/questionCode.html#!problemId=1069 ###游戏规则有N堆石子。A B两个人轮流拿，A先拿。每次只能从一堆中取若干个，可将一堆全取走，但不可不取，拿到最后1颗石子的人获胜。假设A B都非常聪明，拿石子的过程中不会出现失误。给出N及每堆石子的数量，问最后谁能赢得比赛。例如：3堆石子，每堆1颗。A拿1颗，B拿1颗，此时还剩1堆，所以A可以拿到最后1颗石子。 此题有个很奇妙的公式就是,如果n堆石子的个数满足 A0^A1^A2……An == 0,则B获胜，否则A获胜。 ###证明如果 A0^A1^A2……An == K！= 0，n堆石子中一定存在一堆石子m，Am的最高位&gt;= k，那么A一定可以从A堆中取出一定的石子使得K == 0。而当K == 0且游戏没结束时，无论B取出多少个石子，K恒!= 0，故A必胜。如果A0^A1^A2……An == 0时，由于A先取，由上述可知B必胜。 ###代码 12345678910111213141516171819202122232425262728#include &lt;iostream&gt;#include &lt;algorithm&gt;#include &lt;cstring&gt;#include &lt;stdio.h&gt;#include &lt;string&gt;#include &lt;cmath&gt;#define ll long long#define mem(name,value) memset(name,value,sizeof(name))using namespace std;const int maxn = 105;int dp[maxn][maxn];int main()&#123; int n; cin &gt;&gt; n; int x; int sum = 0; for(int i=0;i&lt;n;i++)&#123; scanf("%d",&amp;x); sum ^= x; &#125; if(sum == 0) cout &lt;&lt; "B" &lt;&lt;endl; else cout &lt;&lt; "A" &lt;&lt; endl; return 0;&#125;]]></content>
      <categories>
        <category>计算机</category>
        <category>数据结构与算法</category>
      </categories>
      <tags>
        <tag>博弈</tag>
        <tag>ACM-ICPC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MIT6.824 Lab1-MapReduce]]></title>
    <url>%2F2018%2F06%2F06%2Fmit6-824-lab1%2F</url>
    <content type="text"><![CDATA[前言MIT6.824 是我在学习一些分布式系统方面的知识的时候偶然看到的，然后就开始尝试跟课。不得不说，国外的课程难度是真的大，一周的时间居然要学一门 Go 语言，然后还要读论文，进而做MapReduce 实验。由于 MR（MapReduce） 框架需要建立在 DFS（Distributed File System）的基础上实现，所以本实验是通过使用多线程来模拟分布式环境。虽然难度上大大降低，但是通过该实验，还是会让我们对 MR 的核心原理有一个较为深刻的认识。做实验之前我们需要先把经典的 MapReduce 论文给看了，窝比较建议直接看英文原文，但如果时间不充裕的话，可以直接在网上找中文的翻译版。刚开始做这个实验的时候真的是一头雾水，完全不知道如何下手。后来发现这个工程有一个自动化测试文件（test_test.go）,每部分实验都会使用这个测试文件里的函数对代码进行测试。我们只要顺着这个测试函数逐步倒推，然后补全代码即可。 Part I: Map/Reduce input and output第一部分是先实现一个顺序版（sequential）的MR，让我们对 MR 的流程有一个大体的认识,并且实现doMap() 和 doReduce() 两个函数。其包含两个测试函数TestSequentialSingle() 和 TestSequentialMany()。 TestSequentialSingle()每个map worker处理一个文件，所以map worker的数量就等于文件的数量。测试单个map worker 和 reduce worker。 1234567func TestSequentialSingle(t *testing.T) &#123; mr := Sequential("test", makeInputs(1), 1, MapFunc, ReduceFunc) mr.Wait() check(t, mr.files) checkWorker(t, mr.stats) cleanup(mr)&#125; TestSequentialMany（）此测试函数测试多个 map worker 和多个 reduce worker。其运行逻辑和TestSequentialSingle类似。 1234567func TestSequentialMany(t *testing.T) &#123; mr := Sequential("test", makeInputs(5), 3, MapFunc, ReduceFunc) mr.Wait() check(t, mr.files) checkWorker(t, mr.stats) cleanup(mr)&#125; Sequential()测试函数将工作名称，测试文件，reduce 的数量，用户定义的 map 函数，reduce 函数五个实参传递给Sequential() 123456789101112131415161718192021222324// Sequential runs map and reduce tasks sequentially, waiting for each task to// complete before running the next.func Sequential(jobName string, files []string, nreduce int, mapF func(string, string) []KeyValue, reduceF func(string, []string) string,) (mr *Master) &#123; mr = newMaster("master") go mr.run(jobName, files, nreduce, func(phase jobPhase) &#123; switch phase &#123; case mapPhase: for i, f := range mr.files &#123; doMap(mr.jobName, i, f, mr.nReduce, mapF) &#125; case reducePhase: for i := 0; i &lt; mr.nReduce; i++ &#123; doReduce(mr.jobName, i, mergeName(mr.jobName, i), len(mr.files), reduceF) &#125; &#125; &#125;, func() &#123; mr.stats = []int&#123;len(files) + nreduce&#125; &#125;) return&#125;`Sequential()`首先获取一个`Master` 对象的指针，然后利用函数闭包运行`Master.run()`。 Master.run()123456789101112131415161718192021222324252627282930// run executes a mapreduce job on the given number of mappers and reducers.//// First, it divides up the input file among the given number of mappers, and// schedules each task on workers as they become available. Each map task bins// its output in a number of bins equal to the given number of reduce tasks.// Once all the mappers have finished, workers are assigned reduce tasks.//// When all tasks have been completed, the reducer outputs are merged,// statistics are collected, and the master is shut down.//// Note that this implementation assumes a shared file system.func (mr *Master) run(jobName string, files []string, nreduce int, schedule func(phase jobPhase), finish func(),) &#123; mr.jobName = jobName mr.files = files mr.nReduce = nreduce fmt.Printf("%s: Starting Map/Reduce task %s\n", mr.address, mr.jobName) schedule(mapPhase) schedule(reducePhase) finish() mr.merge() fmt.Printf("%s: Map/Reduce task completed\n", mr.address) mr.doneChannel &lt;- true&#125; doMap()doMap() 和 doReduce()是需要我们去实现的函数。doMap()的实现主要是将用户定义的MapFunc()切割的文本，通过 hash 分到 ‘nReduce’个切片中去。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124func doMap( jobName string, // the name of the MapReduce job mapTaskNumber int, // which map task this is inFile string, nReduce int, // the number of reduce task that will be run ("R" in the paper) mapF func(file string, contents string) []KeyValue,) &#123; // read contents from 'infile' dat,err := ioutil.ReadFile(inFile) if err != nil &#123; log.Fatal("doMap: readFile ", err) &#125; //transfer data into ‘kvSlice’ according to the mapF() kvSlice := mapF(inFile, string(dat)) //divide the ‘kvSlice’ into 'reduceKv' according to the ihash() var reduceKv [][]KeyValue // temporary variable which will be written into reduce files for i:=0;i&lt;nReduce;i++ &#123; s1 := make([]KeyValue,0) reduceKv = append(reduceKv, s1) &#125; for _,kv := range kvSlice&#123; hash := ihash(kv.Key) % nReduce reduceKv[hash] = append(reduceKv[hash],kv) &#125; //write 'reduceKv' into ‘nReduce’ JSON files for i := 0;i&lt;nReduce;i++ &#123; file,err := os.Create(reduceName(jobName,mapTaskNumber,i)) if err != nil &#123; log.Fatal("doMap: create ", err) &#125; enc := json.NewEncoder(file) for _, kv := range reduceKv[i]&#123; err := enc.Encode(&amp;kv) if err != nil &#123; log.Fatal("doMap: json encodem ", err) &#125; &#125; file.Close() &#125;&#125;``` ### doReduce()`doReduce()`主要是将 key 值相同的 value 打包发送给用户定义的 `ReduceFunc()`，获得一个新的 kv对，key 值不变，而value值则是`ReduceFunc()`的返回值，排序，最后将新的 kv对 切片写入文件。```golangtype ByKey []KeyValuefunc (a ByKey) Len() int &#123; return len(a) &#125;func (a ByKey) Swap(i, j int) &#123; a[i],a[j] = a[j],a[i] &#125;func (a ByKey) Less(i, j int) bool &#123; return a[i].Key &lt; a[j].Key &#125; func doReduce( jobName string, // the name of the whole MapReduce job reduceTaskNumber int, // which reduce task this is outFile string, // write the output here nMap int, // the number of map tasks that were run ("M" in the paper) reduceF func(key string, values []string) string,) &#123; //read kv slice from the json file var kvSlice []KeyValue for i := 0;i&lt;nMap;i++&#123; //file, _ := os.OpenFile(reduceName(jobName,i,reduceTaskNumber), os.O_RDONLY, 0666) file,err := os.Open(reduceName(jobName,i,reduceTaskNumber)) if err != nil &#123; log.Fatal("doReduce: open ", err) &#125; var kv KeyValue dec := json.NewDecoder(file) for&#123; err := dec.Decode(&amp;kv) kvSlice = append(kvSlice,kv) if err == io.EOF &#123; break &#125; &#125; file.Close() /********/ //此处如果用 defer，可能会造成文件开启过多，造成程序崩溃 /********/ &#125; //sort the intermediate kv slices by key sort.Sort(ByKey(kvSlice)) //process kv slices in the reduceF() var reduceFValue []string var outputKv []KeyValue var preKey string = kvSlice[0].Key for i,kv := range kvSlice&#123; if i == (len(kvSlice) - 1) &#123; reduceFValue = append(reduceFValue, kv.Value) outputKv = append(outputKv, KeyValue&#123;preKey, reduceF(preKey, reduceFValue)&#125;) &#125; else &#123; if kv.Key != preKey &#123; outputKv = append(outputKv, KeyValue&#123;preKey, reduceF(preKey, reduceFValue)&#125;) reduceFValue = make([]string, 0) &#125; reduceFValue = append(reduceFValue, kv.Value) &#125; preKey = kv.Key &#125; //write the reduce output as JSON encoded kv objects to the file named outFile file,err := os.Create(outFile) if err != nil &#123; log.Fatal("doRuduce: create ", err) &#125; defer file.Close() enc := json.NewEncoder(file) for _, kv := range outputKv&#123; err := enc.Encode(&amp;kv) if err != nil &#123; log.Fatal("doRuduce: json encode ", err) &#125; &#125;&#125; Part II: Single-worker word count第二部分是实现mapF() 和 reduceF()函数，来实现通过顺序 MR统计词频的功能。比较简单，就直接放代码了。 123456789101112131415161718192021222324func mapF(filename string, contents string) []mapreduce.KeyValue &#123; f := func(c rune) bool &#123; return !unicode.IsLetter(c) &#125; var strSlice []string = strings.FieldsFunc(contents,f) var kvSlice []mapreduce.KeyValue for _,str := range strSlice &#123; kvSlice = append(kvSlice, mapreduce.KeyValue&#123;str, "1"&#125;) &#125; return kvSlice&#125; func reduceF(key string, values []string) string &#123; var cnt int64 for _,str := range values&#123; temp,err := strconv.ParseInt(str,10,64) if(err != nil)&#123; fmt.Println("wc :parseint ",err) &#125; cnt += temp &#125; return strconv.FormatInt(cnt,10)&#125; Part III: Distributing MapReduce tasks &amp;&amp; Part IV: Handling worker failures第三部分和第四部分可以一起来做，主要是完成schedule()，实现一个通过线程并发执行 map worker 和 reduce worker 的 MR 框架。框架通过 RPC 来模拟分布式计算，并要带有 worker 的容灾功能。 TestBasic()测试函数启动两个线程运行RUnWoker()。 1234567891011121314151617181920212223242526272829303132333435363738394041424344func TestBasic(t *testing.T) &#123; mr := setup() for i := 0; i &lt; 2; i++ &#123; go RunWorker(mr.address, port("worker"+strconv.Itoa(i)), MapFunc, ReduceFunc, -1) &#125; mr.Wait() check(t, mr.files) checkWorker(t, mr.stats) cleanup(mr)&#125;``` ### setup() &amp;&amp; Distributed()```golangfunc setup() *Master &#123; files := makeInputs(nMap) master := port("master") mr := Distributed("test", files, nReduce, master) return mr&#125;``` 通过`mr.startRPCServer()` 启动 master 的 RPC 服务器，然后通过 `mr.run()`进行 worker 的调度。```golang// Distributed schedules map and reduce tasks on workers that register with the// master over RPC.func Distributed(jobName string, files []string, nreduce int, master string) (mr *Master) &#123; mr = newMaster(master) mr.startRPCServer() go mr.run(jobName, files, nreduce, func(phase jobPhase) &#123; ch := make(chan string) go mr.forwardRegistrations(ch) schedule(mr.jobName, mr.files, mr.nReduce, phase, ch) &#125;, func() &#123; mr.stats = mr.killWorkers() mr.stopRPCServer() &#125;) return&#125; Master.forwardRegistrations()该函数通过worker 的数量来判断是否有新 worker 启动，一旦发现有新的 worker 启动，则使用管道（ch）通知schedule()。理解该函数对实现后面的schedule()至关重要。 1234567891011121314151617181920// helper function that sends information about all existing// and newly registered workers to channel ch. schedule()// reads ch to learn about workers.func (mr *Master) forwardRegistrations(ch chan string) &#123; i := 0 for &#123; mr.Lock() if len(mr.workers) &gt; i &#123; // there's a worker that we haven't told schedule() about. w := mr.workers[i] go func() &#123; ch &lt;- w &#125;() // send without holding the lock. i = i + 1 &#125; else &#123; // wait for Register() to add an entry to workers[] // in response to an RPC from a new worker. mr.newCond.Wait() &#125; mr.Unlock() &#125;&#125; schedule()shedule()虽然不长，但实现起来还是有点难度的。waitGroup用来判断任务是否完成。registerChan来监听是否有新的 worker 启动，如果有的话，就启动一个线程来运行该 worker。通过新开线程来运行新 worker的逻辑比较符合分布式 MR 的特点。对于 宕掉的worker执行call()操作时，会返回false。每开始执行一个任务，就让waitGroup减一，而执行失败（call()返回 false）则将waitGroup加一，代表会将该任务安排给其他 worker。 waitGroup.Wait()则会等到任务完全执行完返回。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748func schedule(jobName string, mapFiles []string, nReduce int, phase jobPhase, registerChan chan string) &#123; var ntasks int var n_other int // number of inputs (for reduce) or outputs (for map) switch phase &#123; case mapPhase: ntasks = len(mapFiles) n_other = nReduce case reducePhase: ntasks = nReduce n_other = len(mapFiles) &#125; fmt.Printf("Schedule: %v %v tasks (%d I/Os)\n", ntasks, phase, n_other) // All ntasks tasks have to be scheduled on workers, and only once all of // them have been completed successfully should the function return. // Remember that workers may fail, and that any given worker may finish // multiple tasks. waitGroup := sync.WaitGroup&#123;&#125; waitGroup.Add(ntasks) taskChan := make(chan int, ntasks) for i:=0;i&lt;ntasks;i++ &#123; taskChan &lt;- i &#125; go func() &#123; for &#123; ch := &lt;- registerChan go func(c string) &#123; for &#123; i := &lt;- taskChan if call(c,"Worker.DoTask", &amp;DoTaskArgs&#123;jobName, mapFiles[i],phase,i,n_other&#125;,new(struct&#123;&#125;))&#123; waitGroup.Done() &#125; else&#123; taskChan &lt;- i &#125; &#125; &#125;(ch) &#125; &#125;() waitGroup.Wait() fmt.Printf("Schedule: %v phase done\n", phase)&#125; RunWorker()通过RunWorker() 来增加 worker。nRPC来控制 worker 的寿命，每接收一次 rpc 请求就 -1s。如果初始值为 -1，则代表改 worker 是永生的。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566// RunWorker sets up a connection with the master, registers its address, and// waits for tasks to be scheduled.func RunWorker(MasterAddress string, me string, MapFunc func(string, string) []KeyValue, ReduceFunc func(string, []string) string, nRPC int,) &#123; debug("RunWorker %s\n", me) wk := new(Worker) wk.name = me wk.Map = MapFunc wk.Reduce = ReduceFunc wk.nRPC = nRPC rpcs := rpc.NewServer() rpcs.Register(wk) os.Remove(me) // only needed for "unix" l, e := net.Listen("unix", me) if e != nil &#123; log.Fatal("RunWorker: worker ", me, " error: ", e) &#125; wk.l = l wk.register(MasterAddress) // DON'T MODIFY CODE BELOW for &#123; wk.Lock() if wk.nRPC == 0 &#123; wk.Unlock() break &#125; wk.Unlock() conn, err := wk.l.Accept() if err == nil &#123; wk.Lock() wk.nRPC-- wk.Unlock() go rpcs.ServeConn(conn) &#125; else &#123; break &#125; &#125; wk.l.Close() debug("RunWorker %s exit\n", me)&#125;``` ## Part V: Inverted index generation第五部分是实现倒排索引。此处要求的倒排索引，就是在输出结果时，需要将出现过 key 值文件的文件名在 key 值后面输出。 功能是通过完成 `mapF()` 和 `reduceF()` 来实现的。 ### mapF()将key 值所在文件的文件名赋给 kv对 的value。```golangfunc mapF(document string, value string) (res []mapreduce.KeyValue) &#123; f := func(c rune) bool &#123; return !unicode.IsLetter(c) &#125; var strSlice []string = strings.FieldsFunc(value,f) var kvSlice []mapreduce.KeyValue for _,str := range strSlice &#123; kvSlice = append(kvSlice, mapreduce.KeyValue&#123;str, document&#125;) &#125; return kvSlice&#125; reduceF()将相同 key 值的所有 value 打包并统计数量返回。 func reduceF(key string, values []string) string { var cnt int64 var documents string set := make(map[string]bool) for _,str := range values{ set[str] = true } var keys []string for key := range set{ if set[key] == false{ continue } keys = append(keys,key) } sort.Strings(keys) for _,key := range keys{ cnt++ if cnt &gt;= 2{ documents += "," } documents += key } //return strconv.FormatInt(cnt,10) return strconv.FormatInt(cnt,10) + " " + documents } 后记从刚开始的无从下手，到现在通过Lab1全部测试，MR 实验算是完全做完了，还是很有成就感的。除了对 MR 有一个更深的理解之外，也深深感受到了优秀系统的魅力——功能强大，结构简洁。同时又了解了一门新语言——GoLang，一门专门为高并发系统而设计的语言，用起来还是很舒服的。但这毕竟是分布式系统的第一个实验，欠缺的知识还很多，继续努力。]]></content>
      <categories>
        <category>计算机</category>
        <category>操作系统</category>
      </categories>
      <tags>
        <tag>分布式系统</tag>
        <tag>MIT6.824</tag>
        <tag>MapReduce</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2018%2F06%2F06%2Fhello-world%2F</url>
    <content type="text"><![CDATA[这篇随笔就用来总结一下自己最近的生活，谈谈自己对未来的想法好了。作为博客的第一篇文章，名字就叫 Hello World 了。 搭建博客之前一直是在 CSDN 上写博客，CSDN 虽然使用简单方便，但是广告太多，界面也有些简陋，用起来不是很舒服。所以我就想着自己搭一个好了，还能记录一些非技术性的东西（主要是最近在养伤，算是比较闲，就想折腾一下）。其实之前是有一个基于 Github Pages 的博客的，但是上一个Github 账号删除的时候忘记保存，博客也就没了= =。 专业方向从去年12月乌鲁木齐站结束到现在，ACM-ICPC 生活结束已经半年了。之前打 ACM-ICPC 的时候，不用想太多，就好好刷题，好好准备比赛和期末考试就好了。但 ACM-ICPC比赛总归是一道道的题，将来无论是工作还是深造，还是要落实到工程或者科研上的。所以这半年我也尝试不少新东西，寻找一下自己感兴趣的方向。很多人都说打 ACM-ICPC的算法好，退役后肯定是继续学像机器学习这样人工智能的东西，将来做一个高大上的算法工程师啊。确实，像人工智能算法做的好的话，价值还是很大的。但是我对纯算法的工作好像并不感兴趣，我更偏爱开发方面的工作，喜欢做偏计算机，而不是数学方向的工作。所以我未来理想的工作，是希望能够进入一个纯技术，像中间件， 云计算这样的团队进行底层系统的开发。&lt;!–&gt; 挂实习现在大三，面临着工作还是读研的问题。其实刚上大学的时候，是希望毕业就去工作的。那时候自信满满，觉得自己努力三年，绝对会在毕业斩获无数 offer。但是现实无情打脸，连实习都没找到= =（话说，ACM-ICPC银牌在找工作，尤其是开发方面的工作的时候，作用好像挺小的，估计主要还是我工程方面知识是在太差了，但银牌起码过 BAT 的简历应该没问题）。AT 两家跪掉之后，发现自己工程方面的知识不是一两天能突击回来的，就不想再找实习了，便专心保研了。 保研前一段时间对保研这件事耿耿于怀，总担心自己上不了好学校。但是在养伤期间（蓝桥杯归途出了些意外，头部缝了n针）心态也逐渐放平和了。我将来并不想走科研的道路，打算硕士毕业就工作了，所以学校的影响好像并不大。况且最差也是保本校，窝工虽然不上什么顶尖学校，但好歹也是双一流，应该不至于有学历歧视吧。所以不管去哪读书，只要方向合适，导师和善，我都能接受。 尾语一个人的命运啊,既要考虑历史的进程,也要靠个人的奋斗! 希望自己能保持对技术的热情，在这样一个互联网的时代中留下一些属于自己的痕迹吧。]]></content>
      <categories>
        <category>随笔</category>
      </categories>
      <tags>
        <tag>生活</tag>
      </tags>
  </entry>
</search>
